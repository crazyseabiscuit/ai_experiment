## useful URL

gpt analysis： https://artificialanalysis.ai/models/gpt-4

如果模版选择的不准我们也可以使用一些cot的办法

不同的拆分框架
react
P&E
大模型进行反思只要对用户的问题，但是不要对返回的结果进行反思
如何分析问题：逐步分析cot，分解法p&e，反思法react，批判法，假设法
self discovery 速度比较慢
每个思路的范化性也是比较局限的
可以把之前规划之后的结果存成embedding，然后有类似的query就可以直接使用之前的规划

任务规划穿越问题：自己去写dsl来规划
让大模型的输出尽量的短，这样大模型可以相对更加稳定
过滤掉问题中的一些无效的词，减少大模型的扰动
在做缓存的时候可以针对plan的过程和相同的问题进行缓存

因子归因和纬度归因：因子归因 贡献度和精细度
高级诊断系统
离线诊断系统
智能体的回答效率是不是可以通过分布式来计算？

rerank
专家人工评价和大预言模型评价

rag在智能问答上的分享
对于问题要做一部分的处理context window，对于用户的问题进行简单的抽象
pipline 1 通过外部的知识库+LLM
pipline2 直接通过LLM
多轮对话可以使用long/short memory
graph rag本身也是相似度

360************\*\*\*\*************\*************\*\*\*\*************
使用dpo技术进行微调
