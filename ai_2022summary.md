# AI 2022 the darkness before dawn

## table of contents
AI content generation 
AI dev ops
Graph
hardware accumulation
privacy computing and federation learning 

### future trending 
nature language explaination 
personalize 


fully understand the business requirements
data simulation is possible? yeah but it is very hard


AI solution is integrated with cloud services and open source framwork/software, engineering is easy to use them now.we can just download a pretrained model, use just a small dataset to train a machine learning model, even more we can use a existing software or cloud service to fullfill the AI feature for the requirments, so we don't need to train a model by ourself at all,not only normal company, in the early 2022, black industry they use deepface to replace the images and videos human faces to scam and fraud in China. It seems AI technology is very promising and completed for all of us,why the title is "AI 2022 the darkness before dawn"? Why industry agree there are still many blockers from using these technololy to create bussiness values?
The short answer is there are many limitations, AI content genration is very popular recently, We will go through AI content generation like chatGPT firstly.


### AI content generation
chatgpt : optimizing language models fo dialogue , demonstrate how to fullly use the labled data for chat 
disadvantage: it still make simple mistake

personalize is not possible and content 
faceswapzai https://faceswap.dev//
make a video : https://makeavideo.studio/
stable diffusion: Stable Diffusion is a deep learning, text-to-image model released in 2022. It is primarily used to generate detailed images conditioned on text descriptions, though it can also be applied to other tasks such as inpainting, outpainting, and generating image-to-image translations guided by a text prompt.
causality 


## reference



- MAKE A VIDEO  https://makeavideo.studio/

- CogVideo Large-scale Pretraining for Text-to-Video Generation via Transformers  https://models.aminer.cn/cogvideo/

- TOME generative storytelling text context based on power point  https://beta.tome.app/

- GODEL: finetuning phases that require infomration external to the current conversation(e.g., a database or document) to produce good responses


Multimodal large model ： many person are talking about, it also has good performance such as stableDiffusion, chatGPT, in China there are also many institution, company realse large scaled models, there performance are good
recently the industry is focused on if you have a good pretrain model, how to make it best use for subtask for different bussiness scenarios.
Mutimodel trending : leverage different type of data to improve the subtask, Chinese Academy of Sciences use voice and video data to judge the position of person at night or no enough fiber 
AI design relted works such as image generation, video generation
chatGPT and google Lamda almost pass the turing test
KG
faiththful with Graphe methdology 
multiple technology are merged together 
Graph transformer is hot, diffusion model, how to merge it in Gragh,fake detection and EDA related task, not traditional graph problem, how to sovle it with grah methdology and GNN

vision transformer (ViT)
deepmind protein remodeling  AI + Biology

AI system can be very commonly used, it can do something directly 
AIGC machine can create, text to picture

AI for science and AI for industry
AI models growing in complexity and diversity 

Casual Inference:
Related topic : AIGC, big model,privacy computing, Gragh and Machine learning
Industry hot topic: digital transformation
this is another change


- collect demonstration data, and train a supervised policy

## Bottle neck
data preporcessing and business, same scenario you still do them again and again 
most ML models are still memory model, it doesn't perform very well on unseen data, how to explain, how to be small and ROI efficient

the nature of AI does not change, during the testing some of the AI response does not make sense, some tech can reduce this kind of proflem but we can't resolve the problem fundamentally
the edge of AI, we should know,EDA design 99.9 does not useful, we should know understand the edge of AI is very useful for us to make the final decision.
可解释，可信，可控可靠
前后逻辑和事实不符合，范式的改变去解决这些问题，这些困难很难克服，把能用的地方先用起来
可以有大规模图数据的场景是比较少的，能做大规模场景下的图数据的实验少，从学术界的角度也很尴尬，高校基本上是被排除在之外的，更多的 人工智能的范式如果是百花齐放的话，应该会更好一些。

从工程的角度上来说，怎么样让算法人员尽量的少的去和硬件打交道，怎么样把异构的网络cpu和GPU结构组合好，利用系统的能力去做google gsharp 伯克利alpha，做模型的切割，充分的用资源。让所有的任务fill的比较饱满
硬件话和异步化，特定的芯片和高层次的网络结合，用系统的能力，model as service，学校是不是可以跟企业做合作。学校的想象空间更大

make a video和3d生成
autoML： AWS gluon，让机器去寻找最好的神经网络，多目标，而且模型能够轻量。MLOps更加精细化，从数据开始管理。

narrow AI, strong reliance on data,high computing cost is still high
the AI develop is not very balanced, huge companies they have enough computing, data and human resource, but other company of institutions doesn't have enough

## 之后的发展
可信的图神经网络，大模型gpt4会有一些更加惊艳的表现，在内容产生的方向。图神经网络的安全性，也是未来一段时间人工智能急切要解决的问题
把这些大模型做集成会不会有更好得结果？大模型怎么样对小而且精得模型做出一些贡献
AI得通用性，直接就体现出一种能力，和之前得泛化性是不一样得
都是大模型可否专注在一个领域上，这样做一个集成得效果还会好一点
国际地缘政治，芯片等技术开源得问题