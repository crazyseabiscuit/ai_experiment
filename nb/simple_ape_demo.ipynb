{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = ''"
      ],
      "metadata": {
        "id": "HbYuP9fSwDUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies\n",
        "! pip install git+https://github.com/keirp/automatic_prompt_engineer"
      ],
      "metadata": {
        "id": "x82vwepAs3Jg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W5nQxnZsyS1"
      },
      "source": [
        "# Optimizing Prompts with **Automatic Prompt Engineer** (APE)\n",
        "\n",
        "This notebook demonstrates how to use Automatic Prompt Engineer (APE) (arxiv link) to optimize prompts for text generation. In its simplest form, APE takes as input a dataset (a list of inputs and a list of outputs), a prompt template, and optimizes this prompt template so that it generates the outputs given the inputs.\n",
        "\n",
        "APE accomplishes this in two steps. First, it uses a language model to generate a set of candidate prompts. Then, it uses a prompt evaluation function to evaluate the quality of each candidate prompt. Finally, it returns the prompt with the highest evaluation score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbAA6kE5syS5"
      },
      "outputs": [],
      "source": [
        "# First, let's define a simple dataset consisting of words and their antonyms.\n",
        "words = [\"sane\", \"direct\", \"informally\", \"unpopular\", \"subtractive\", \"nonresidential\",\n",
        "    \"inexact\", \"uptown\", \"incomparable\", \"powerful\", \"gaseous\", \"evenly\", \"formality\",\n",
        "    \"deliberately\", \"off\"]\n",
        "antonyms = [\"insane\", \"indirect\", \"formally\", \"popular\", \"additive\", \"residential\",\n",
        "    \"exact\", \"downtown\", \"comparable\", \"powerless\", \"solid\", \"unevenly\", \"informality\",\n",
        "    \"accidentally\", \"on\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUxGByFssyS6"
      },
      "outputs": [],
      "source": [
        "# Now, we need to define the format of the prompt that we are using.\n",
        "\n",
        "eval_template = \\\n",
        "\"\"\"Instruction: [PROMPT]\n",
        "Input: [INPUT]\n",
        "Output: [OUTPUT]\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DX06_wgsyS7",
        "outputId": "7e1b4317-76d3-44f9-9f27-0799a81b8098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating prompts...\n",
            "Model returned 50 prompts. Deduplicating...\n",
            "Deduplicated to 21 prompts.\n",
            "Evaluating prompts...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating prompts: 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished evaluating.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Now, let's use APE to find prompts that generate antonyms for each word.\n",
        "from automatic_prompt_engineer import ape\n",
        "\n",
        "result, demo_fn = ape.simple_ape(\n",
        "    dataset=(words, antonyms),\n",
        "    eval_template=eval_template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXHoK_4esyS8",
        "outputId": "3c8db554-0ea4-4c07-a284-a0aabda810d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score: prompt\n",
            "----------------\n",
            "-0.18:  produce the opposite of the word given.\n",
            "-0.26:  find antonyms for the given words.\n",
            "-0.28:  \"write a word that has the opposite meaning of the word given.\"\n",
            "-0.31:  produce an antonym (opposite) for each word given.\n",
            "-0.31:  \"find an antonym for each word.\"\n",
            "-0.32:  choose the antonym of the word given.\n",
            "-0.35:  produce a list of antonyms.\n",
            "-0.36:  produce an antonym for each word.\n",
            "-0.41:  \"find antonyms for the following words.\"\n",
            "-0.48:  make a list of antonyms.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's see the results.\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PE_bMX2syS9"
      },
      "source": [
        "Let's compare with a prompt written by a human:\n",
        "\n",
        "\"*Write an antonym to the following word.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXkvmnXrsyS9"
      },
      "outputs": [],
      "source": [
        "from automatic_prompt_engineer import ape\n",
        "\n",
        "manual_prompt = \"Write an antonym to the following word.\"\n",
        "\n",
        "human_result = ape.simple_eval(\n",
        "    dataset=(words, antonyms),\n",
        "    eval_template=eval_template,\n",
        "    prompts=[manual_prompt],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elGm3qs3syS-",
        "outputId": "803041d3-4dff-4999-b71e-6f6596c2a159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log(p): prompt\n",
            "----------------\n",
            "-0.24: Write an antonym to the following word.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(human_result)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.8 ('py38')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c2afcb7a2e6fcb9490d448e607abf9226c3f7acca28baeea9bc24b456562037f"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}